## **Description**

- 모형에 대한 생각 (머신러닝(RF, XGBoost 등), 딥러닝 다 됨)

  http://blog.naver.com/PostView.nhn?blogId=y4769&logNo=220024117776

  1. 종속변수가 연속형인 경우

  - 선형회귀분석

    1.1) 독립변수가 1개인 경우

    - 독립 (연속): 단순 선형 회귀분석
    - 독립 (범주):  paired T-test, wilcoxon, 2-sample t-test, mannwhitney, oneway anova, kruskal-wallis

    1.2) 독립변수가 여러 개인 경우

    - 독립(연속): 다중 선형 회귀분석, 

    - 독립(범주): ANOVA(GLM) 

    - 독립(혼합): GLM, 회귀분석(dummy), 머신러닝(RF, XGBoost 등), 딥러닝

      

  2. 종속변수가 범주형인 경우

  - logistic 회귀분석, 나이브베이즈 분류

    2.1) 독립변수가 범주형

    - 카이제곱 분석

    2.2) 독립변수가 연속형 혹은 변수 2개 이상

    - 종속(이진분류): logistic 회귀분석(이분형), 나이브베이즈 분류
    - 서열 (3수준이상): proportional odds model, 순서형 logistic 회귀
    - 종속 (3수준 이상-다중분류): mutinomial logistic 회귀분석, 나이브베이즈 분류(?), 머신러닝(RF, XGBoost 등), 딥러닝

    

- 쓸 때 구성

1. **분석을 위한 변수 정의 및 데이터셋 구성(데이터 마트 구성)**

   공통적으로 모형에 사용되는 종속/독립변수, 관측값의 단위, 표준화 여부, 변수 변환 여부 등이 모두 언급되어야함

   X인자: ID, 시간, 텍스트 고민 필요
         일자, 주차, 월차 기준(시간에 따라) 혹은 특정 건 기준

   Y인자: 불량률 -> 일별 or 시간별 불량률, 각 제품별 불량 여부인지 명확하게 정의

   파생변수 확인, 필요 시 제시해야함
   
   분석 데이터셋 기간 설정(데이터가 특정 기간에만 유효할 경우 특히 중요 뒤에 학습/검증/테스트 기간 정의 필수)
   
   1.1 **독립변수에 time lag가 없는 경우**

   - 데이터 구성에 대한 논의: 데이터셋 key를 기준, 사용자(제품)별로 요약통계량을 만듬
   - 통계량을 만들시 고려해야할 축
     - 시간별: ex per day, week, total...
     - 품목별: 분석목적에 따라 달라지나 대분류, 중분류, 소분류 순으로 선정 (가전제품전체, 에어컨 전체, 대체제, 보완재 페이지)
     - 항목별: count 가능한 RFM 기반 통계량 생성, 마케팅 부서와의 협의 후 고도화
     - RFM - Recency 최근성 (최근방문횟수, 방문주기) / Frequency 빈도 (Total 방문횟수, 장바구니 담은 항목 수) / Monetory 금액(장바구니 담은 품목의 액수)
     - 학습 및 Y변수 기간 고려 필요

   1.2 **독립변수에 time lag가 있는 경우**
   * 같은 공정내에서 데이터 병합 / 공정소요시간 고려 데이터 병합
   - step1) 초단위 데이터를 분단위 데이터로 변경하기 위해 요약통계량을 생성한다.(min, max, mean, mode)
   - step2) 각 공정별 시간차를 반영하여 시간을 기준으로 결합한다.
   - step3) 생산결과 항목을 보고 기준 미달인 경우 1(불량), 0(정상)으로 태깅한다.

   1.3 **디지털 마케팅일 때**

   - step1) 목표 고객의 정의 ("초콜릿"을 장바구니에 넣은 고객)
   - step2) 연관분석을 진행하여 연관 데이터(수집 변수)들의 Lift값을 계산, X변수로 설정 가능
   - step3) 디지털마케팅을 고려하여 분석기간 정의 필요
   - step4) (모델링) 마케팅 반응률 확인 (Lift chart 사용)








2. **모델링**
   **분석유형은 크게 아래와 같이 구분됨**
   1) 이상탐지 (설비이상감지, 이상거래 탐지, 법인카드 부정사용, 시스템 사용량 모니터링, 보안로그 모니터링, 에너지 사용량 모니터링)
   2) 연관성분석, 추천, 소셜빅데이터, 군집화
   3) 수치예측, 수요예측 분류
   4) 영향인자발굴, 최적조건도출 
   
   **공통**
   - (EDA) EDA에서 linear or nonlinear 특징 구분-> 모델링 when linear, when nonlinear 로 꼭 연결
   - (EDA) 아웃라이어 제거: 아웃라이어가 대부분 불량일 경우, 제거 고민 필요 
                           이상치는 Box-plot 활용 가능, 결측치는 각 유형에 따라 보정
   - (EDA) without linear model 반드시 linear No
   - (모델링) focus words - 분석 목적 확인
   - (모델링) picked model 어디에 사용하는지
   - (검증) 현장문제 검증 방법 명확
   - (검증) overfitting 등을 진단, 확인하는 과정 need
   - (검증) consistency 검증방법 언급 필요 (모델링 검증을 여러번해서 일관성을 확인하는건가?)
   

   **예측 모델일 경우**

   2.1 EDA와 전처리(EDA- 모델링 생각하자)

   - 전처리로 수치형은 표준화(평균 추세 대비 벗어난 정도 파악), 범주형의 경우 onehot encoding
   - 변수별 unit이 크게 다를 때 (배치별로 변동성 크고, 배치 내에서도 변동성 클 때), 영향성을 최소화하는 전처리 가정을 거쳐야함

   2.2 데이터/모델링 진단 과정

   - 변수선택: lasso 또는 RF의 변수 중요도를 이용하여 변수 선정 후 모델 알고리즘 사용하여 0~1사이(또는 다른 예측치) 지표 생성
   - train / test 분리
     - train, test로만 분리할지(k-fold 교차검증사용) train, valid, test 데이터셋 3개로 분리할지 고민
     - 데이터 수가 적다면 train, test로 분리 후 cross-validation 방법을 사용함 (valid: 모델 성능을 평가하기 위해, 일반화된 모델을 얻기 위해)
     - 순차적으로 분리할지(시계열 데이터 등 시간 순서를 유지해줘야하는 경우), 무작위 샘플링을 할지
   - 데이터 클래스 불균형이 있는 경우
     - 더 많은 수의 클래스를 기준으로 모델링이 치우칠 수 있는 우려가 있음
     - 더 적은 클래스 데이터에 더 큰 가중치를 주거나, 데이터가 더 적은 쪽을 잘못 분류했을 때 더 많은 loss를 부과
     - 훈련데이터에서 언더샘플링 혹은 오버 샘플링 기법을 사용하여 클래스 비율을 균등하게 맞춰줌
   - 컬럼이 row건보다 많을 경우 PLS기법을 사용하는 것이 바람직함, 그렇지 않다면 뉴럴넷, 램덤포레스트 등의 방법을 사용해도 됨
   - 모델링 진단 - 모형이 잘 학습되었는지 검증
     - 예측모델이 잘 생성되었는 평가하는 방법
     - ROC curve, AUC, Lift chart 등을 이용하여 모형의 overfitting 및 underfitting을 확인한다.

   2.3 검증 방안 기준

   1. 모형 검증 기간

   - 단순하게 데이터 / 학습 기간을 가지고 검증 가능함

   - 특정 기간(N개월)을 기준으로 데이터 학습/검증 기간을 이동하여 전체 기간 검증(moving window)

     예시) 퇴직 예측, 직원 ID key 값으로 하여 특정 N개월 데이터를 결합하여 학습 루 다음 달 데이터 검증

   2. 현장에서 사용가능한지 성능 검증

   - test 데이터셋으로 정확도, recall, precision 의 성능을 고려함
   
   - 특히 recall 이나 precision 은 불균형 클래스에서 중요함

   2.4 분석모형 활용 측면 검증, 개선

   - 모델링 이후 새로운 데이터를 학습데이터 형태(컬럼 등)로 만든 후 아래 전처리 수행

   - 전처리 스케일링을 했다면, 모델링에서 사용한 컬럼별 mean 과 variance로 스케일링 진행

   - 전처리 onehot encording 을 했다면, 모델링에서 사용한 onehot 컬럼에 맞춰 컬럼 변형 진행 위 내용으로 입력값을 넣으면 (목표 Y)를 예측할 수 있다.
   
   - consistency 검증방법 언급 필요

     

   **원인탐지(분석) / 최적 운영조건 도출 / 영향인자 발굴인 경우**
   - 일반적으로 tree 계열 model로 영향인자를 발굴하고(feature imp) node가 분할되는 것을 확인하여 최적 조건을 도출함 

   2.1 EDA와 전처리

   - 7개 setting value들에 대한 4개의 요약통계량을 독립변수로 (총 28개) OK_NG(0,1)를 종속변수로 하여 RF모델 적합

   2.2 데이터/모델링 진단과정
   
   - Tree 계열 앙상블 모델로 변수 중요도 산출하여 중요도 높은 인자를 영향인자로 도출
   - 중요도 순위 상위~개(현업과 협의)인자로 Decision Tree 적용해보고 분류가 되는 범위 확인
   - [최적운영조건] decision tree 모델링 시 말단 node는 양품비율에 따라 분류됨
     양품 비율 가장 high한 말단 node로 가기 위한 조건 = 최적운영조건

   2.3 검증 방안 기준

   - 변수별 값 범위 EDA를 통해 수율이 낮은 구간 검증
   - 미래 데이터 적용을 통해 모델 성능 검증

   2.4 분석모형 활용 측면 검증, 개선

   - 협업과 협의 후 중요인자별 최적 운영조건 정리
   - 주기기적으로 최적운영 조건에 맞춰 운전 방식 조정

   2.5 최적 투입량 분석(시뮬레이션 방법론)

   - 공정별 setting value조합인 recipe를 정리, 수율 순으로 내림차순 정렬하여 가장 높은 수율일때의 recipe를 추치함

   

   **추천 모델일 경우**

   - 행동일 경우 행동에 대한 로그를 수집(시간에 따라 혹은....) 행동 그룹 만듬

   - 행동 그룹별로 발생 빈도를 산출함

   - 발생 빈도에 따라 단발성 행동 그룹과 반복행동 그룹으로 분류

   - 어떤 행동 시 해당 행동이 속한 반복그룹 검색

   - 가장 빈도가 높은 그룹 선택하고 그룹내 행동들을 소비자에 추천

     혹은 앞의 행동 X, 뒤에 행동 Y로 놓고 머신러닝 학습

   - 다음 행동 추천

   

   **배치 진행 도중까지의 데이터만으로 예측하고 싶을때**

   - 평균 trajectory 따른다고 가정하고 0으로 채워 넣어 예측
   - 현재 값을 유지한다고 가정하고 현재값을 채워 넣어 예측
   - PCA 모델링을 통해 예측값을 채워넣어 예측
   - 변수별로 Time Series 모델링을 한 후, 예측값을 채워 넣어 예측
